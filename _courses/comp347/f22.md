---
layout: class
title: "COMP 347: Applied Machine Learning, Fall 2022"
catalog-desc: (todo) Using statistics to design algorithms that can learn from data.
semester: f22
---

*{{ site.data.policies.syllabus_deviation_v2 }}*

* toc
{:toc}

## Logistics

* Class meetings: MWF 1:00 PM - 1:50 PM in CSB 303
* Instructor: Robert Utterback
  * Office: {{ site.data.me.office }}
  * [Zoom Room]({{ site.data.me.zoom }})
  * Phone: {{ site.data.me.phone }}
  * [Website]({{ site.url }})
  * [Email](mailto:{{ site.email }})
  * Office hours: {{ site.data.semesters[page.semester].office_hours }}
* Website: <a href="{{ site.url }}{{ page.url }}">{{ site.url }}{{ page.url }}</a>
* Credits: 1 course credit
* Prerequisites: COMP 151 and MATH 260. COMP 152 recommended.
* Feedback: At any time during the course you can use
  [this]({{ site.data.semesters[page.semester].feedback_form }}) to provide
  anonymous suggestions, criticism, praise, etc.

## Content

### Description

An introduction to machine learning with topics in data science and
data mining. The course aims to supply students with a useful toolbox
of machine learning techniques that can be applied to real-life
data. Techniques may include logistic and linear regression, SVMs,
decision trees, neural networks, and clustering. The focus will be on
developing important skills in preparing data and selecting and
evaluating models, though we will delve into the mathematical
intuition behind each model.

### Topics

Possible topics include:

* Python for data science and visualization
* Linear models for regression
* Linear models for classification
* Preprocessing, feature selection and engineering
* Support vector machines
* Trees, forests, and ensembles
* Gradient boosting
* Model Evaluation and Selection
* Dimensionality reduction
* Clustering
* Word embeddings
* Neural Networks

### Learning Objectives

* An understanding of the types of machine learning and the intuition behind the techniques listed above
* An ability to analyze real-world data and prepare it for learning/mining via data cleaning
* An ability to add, remove, and modify data features and evaluate their effect on ML models
* An ability to compare and evaluate the performance of several ML models on a particular dataset
* An ability to communicate algorithmic findings and effectively present results through visualization

### Sources

The required course textbook is:

Géron, Aurélien. *Hands-On Machine Learning with Scikit-Learn, Keras,
and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent
Systems* (2nd edition). O'Reilly. 2019. ISBN-13: 978-1492032649

I also recommend, but do not require:

Guido, Sarah and Muller, Andreas. *Introduction to Machine Learning
with Python*. O'Reilly. 2016. ISBN-13: 978-1449369415.

We might also use some material from:

Deisenroth, Marc Peter and Faisal, A. Aldo and Ong, Cheng
Soon. *Mathematics for Machine Learning*. Cambridge University
Press. 2020. ISBN-13: 978-1108455145. Available at
[https://mml-book.github.io/](https://mml-book.github.io/).

### Programming Environment

We'll be using Python 3 along with several of the standard data
science libraries available, including matplotlib, pandas, numpy, and
scikit-learn, among others. The easiest way to get set up is to
install the [Anaconda](https://www.anaconda.com/) Python distribution,
which includes everything you need. It also includes the Spyder IDE
for development, although you are free to develop in any text editor
you like. You may also use the department server if you'd like; just
send me an email.

## Policies

* **Late assignments**: {{ site.data.policies.late_days_v4 }}

* **Academic dishonesty**: {{ site.data.policies.cheating_v1 }}

* **Collaboration**: {{ site.data.policies.collab_v2 }}

* **Electronic devices**: {{ site.data.policies.electronics_v1 }}

* **General expectations**: {{ site.data.policies.expectations_v1 }}

## Assessment

### Assignments

The course workload is as follows:

| Category      | Number of Assignments | Final Grade Weight |
| :-----        |              -------: |                 -: |
| Homework      |                  5--7 |                50% |
| Midterm       |                     1 |                20% |
| Final         |                     1 |                20% |
| Participation |                     - |                10% |

Most (probably all) homework assignments will involve
programming. Each exam focuses primarily, but not necessarily
exclusively, on material covered since the previous exam. In other
words, the final exam may include one or two questions from first-half
material.

Your participation grade is based on a variety of activities. During
class I will often make sure of the
[Socrative](https://socrative.com/) app, so you'll need to install
this on your phones. Participating in Socrative questions and with
in-class group activities is required for a decent participation
grade; a full grade also includes asking questions either in class or
in office hours.

### Grading

Your final grade is based on a weighted average of particular
assignment categories, with weights shown above. You can estimate your
current grade based on your scores and these weights. You may always
visit the instructor *outside of class* to discuss your current
standing.

{{ site.data.policies.gradescale_std_v1 }}

### Workload

The weekly workload for this course will vary by student and over the
semester, but on average should be about 12 hours per week. The follow
table provides a rough estimate of the distribution of this time over
different course components for a 16 week semester.

| Category                     |   Total Time |     Time/Week (Hours) |
| :-----                       |     -------: |    -----------------: |
| Lectures                     |           55 |                   2.5 |
| Homework                     |           72 |                   4.5 |
| Exam Study                   |           27 |                   1.5 |
| Reading+Unstructured Study   |              |                   2.5 |
| ============================ | ============ | ===================== |
|                              |              |                    11 |

## Schedule
The following **tentative** calendar should give you a feel for how
work is distributed throughout the semester. Assignments and events
are listed in the week they are due or when they occur. *This calendar
is subject to change based on the circumstances of the course*.

<!-- (let* ((start-date (org-read-date nil nil "2018-08-21")) -->
<!--        (end-date (org-read-date nil nil "2018-12-05")) -->
<!--        (days (list "Mon" "Tue" "Wed" "Fri")) -->
<!--        (current start-date)) -->
<!--   (while (string< current end-date) -->
<!--     (let* ((time (org-time-string-to-time current)) -->
<!--            (day (format-time-string "%a" time))) -->
<!--       (if (member day days) -->
<!--           (princ (concat (format-time-string "%a %m/%d" time) "\n")))) -->
<!--     (setq current (org-read-date nil nil "++1" nil (org-time-string-to-time current))))) -->

{: .schedule}
| Date                  | Topic                                              | Assignment/Reading                                      |
| :-----                | :--:                                               | --:                                                     |
| Wed 08/24 (Week 1)    | [Intro and Logistics][7]                           |                                                         |
| Fri 08/26             | [ML Landscape][8]                                  | Ch. 1 (p. 1--32)                                        |
|-----------------------+----------------------------------------------------+---------------------------------------------------------|
| Mon 08/29 (Week 2)    | [Python Libs][9], [NumPy][4]                       | [NumPy Tutorial][1], [Hwk 1](hwk1.ipynb)                |
| Wed 08/31             | [Pandas][5]                                        | [Pandas Tutorials][2] (all except time series)          |
| Fri 09/02             | [Visualization][10] ([matplotlib][6])              | [Matplotlib Basic Usage][3]                             |
|-----------------------+----------------------------------------------------+---------------------------------------------------------|
| Mon 09/05 (Week 3)    | [Regression Case Study][11] ([notebook][12])       | p. 35--61                                               |
| Wed 09/07             | [Model Selection & Validation][13]                 | p. 62--83                                               |
| Fri 09/09             | [Preprocessing I][14]                              | [Hwk 2](hwk2.ipynb)                                     |
|-----------------------+----------------------------------------------------+---------------------------------------------------------|
| Mon 09/12 (Week 4)    | Preprocessing II                                   | p. 85--100                                              |
| Wed 09/14             | Imputation; [Binary Classification Evaluation][15] | p. 100--109                                             |
| Fri 09/16             | [Multiclass Classification][15]                    |                                                         |
|-----------------------+----------------------------------------------------+---------------------------------------------------------|
| Mon 09/19 (Week 5)    | [Calibration & Imbalanced Data][16]                |                                                         |
| Wed 09/21             | [Calculus Review][17]                              | [3blue1brown][19] (Ch. 1-5)                             |
| Fri 09/23             | [Basic Linear Algebra][18]                         | [3blue1brown][20] (All but ch. 12), [Hwk 3](hwk3.ipynb) |
|-----------------------+----------------------------------------------------+---------------------------------------------------------|
| Mon 09/26 (Week 6)    | Training Models                                    | p. 111--128, [Hwk 3 Leaderboard](hwk3-scores)           |
| Wed 09/28             | [Feature Engineering][21] ([notebook][22])         |                                                         |
| Fri 09/30             | [Complexity & Regularization][23]                  | p. 128--142                                             |
|-----------------------+----------------------------------------------------+---------------------------------------------------------|
| Mon 10/03 (Week 7)    | (Class Cancelled)                                  | p. 142--151                                             |
| Wed 10/05             | [Logistic Regression and SVMs][24]                 | p. 153--164                                             |
| Fri 10/07             | [SVM Kernels][25]                                  | p. 164--174                                             |
|-----------------------+----------------------------------------------------+---------------------------------------------------------|
| Mon 10/10 (Week 8)    | **Midterm**                                        |                                                         |
| (Wed 10/12)           | (Fall Break)                                       |                                                         |
| (Fri 10/14)           | (Fall Break)                                       |                                                         |
|-----------------------+----------------------------------------------------+---------------------------------------------------------|
| Mon 10/17 (Week 9)    | Midterm Solutions                                  |                                                         |
| Wed 10/19             | [Decision Trees][26]                               | p. 175--187                                             |
| Fri 10/21             | [Ensembles][27]                                    | p. 189--211                                             |
|-----------------------+----------------------------------------------------+---------------------------------------------------------|
| Mon 10/24 (Week 10)   | Hwk3 Questions                                     |                                                         |
| Wed 10/26             | (No class -- work on Hwk3)                         |                                                         |
| Fri 10/28             | [Model Interpretation & Feature Selection][28]     |                                                         |
|-----------------------+----------------------------------------------------+---------------------------------------------------------|
| Mon 10/31 (Week 11)   | [Dimensionality Reduction][29]                     | Ch. 8                                                   |
| Wed 11/02             | [Clustering][30]                                   |                                                         |
| Fri 11/04             | Mixture Models                                     |                                                         |
|-----------------------+----------------------------------------------------+---------------------------------------------------------|
| Mon 11/07 (Week 12)   | (No class)                                         |                                                         |
| Wed 11/09             | NMF and Outlier Detection                          |                                                         |
| Fri 11/11             | Working with Text                                  |                                                         |
|-----------------------+----------------------------------------------------+---------------------------------------------------------|
| Mon 11/14 (Week 13)   | More Text: Topic Models                            | [Hwk 4](hwk4.ipynb)                                     |
| Wed 11/16             | LDA                                                | [Final Project](final-proj.pdf)                         |
| Fri 11/18             | Word and Document Embeddings                       |                                                         |
|-----------------------+----------------------------------------------------+---------------------------------------------------------|
| Mon 11/21 (Week 14)   | Hwk 3 Review                                       |                                                         |
| (Wed 11/23)           | (Thanksgiving Break)                               |                                                         |
| (Fri 11/25)           | (Thanksgiving Break)                               |                                                         |
|-----------------------+----------------------------------------------------+---------------------------------------------------------|
| Mon 11/28 (Week 15)   | Neural Networks                                    | Ch. 10                                                  |
| Wed 11/30             |                                                    |                                                         |
| Fri 12/02             | Training Neural Networks                           | Ch. 11, [Hwk 5](hwk5.ipynb)                             |
|-----------------------+----------------------------------------------------+---------------------------------------------------------|
| Mon 12/05 (Week 16)   | Transfer Learning; RNNs                            |                                                         |
| Wed 12/07             | Transformers                                       |                                                         |
| ======                | =======                                            | ======                                                  |
| **Sat 12/10** 3:00 PM | **Final Exam**                                     |                                                         |

[1]: https://numpy.org/devdocs/user/absolute_beginners.html
[2]: https://pandas.pydata.org/docs/getting_started/intro_tutorials/index.html
[3]: https://matplotlib.org/stable/tutorials/introductory/usage.html
[4]: https://github.com/ageron/handson-ml2/blob/master/tools_numpy.ipynb
[5]: https://github.com/ageron/handson-ml2/blob/master/tools_pandas.ipynb
[6]: https://github.com/ageron/handson-ml2/blob/master/tools_matplotlib.ipynb
[7]: ./00-intro.html
[8]: ./01-landscape.ipynb
[9]: ./02-py-libs-overview.html
[10]: ./04-viz.html
[11]: ./05-case-study-regression.pdf
[12]: ./05-regression-case-study.ipynb
[13]: ./06-model-selection.html
[14]: ./07-preprocessing.html
[15]: ./09-classification.html
[16]: ./11-imbalance.html
[17]: https://github.com/ageron/handson-ml2/blob/master/math_differential_calculus.ipynb
[18]: https://github.com/ageron/handson-ml2/blob/master/math_linear_algebra.ipynb
[19]: https://www.3blue1brown.com/topics/calculus
[20]: https://www.3blue1brown.com/topics/linear-algebra
[21]: ./15-feature-engineering.html
[22]: ./15-feature-engineering.ipynb
[23]: ./16-regularization.html
[24]: ./17-logreg-svm.html
[25]: ./18-kernels.html
[26]: ./19-trees.html
[27]: ./20-ensembles.html
[28]: ./21-interp-select.html
[29]: ./22-dimred.html
[30]: https://amueller.github.io/COMS4995-s20/slides/aml-14-clustering-mixture-models/

## Monmouth College Services

{{ site.data.policies.services_2223 }}

<!-- Local Variables: -->
<!-- eval: (orgtbl-mode) -->
<!-- End: -->
