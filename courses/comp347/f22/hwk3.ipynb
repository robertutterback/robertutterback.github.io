{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3 -- <<Name(s) here>>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Due Friday, October 28 by midnight**. You may submit this assignment in groups of 2. Be sure to put your names above. Also, don't forget to submit your data files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this homework is to provide a realistic setting for a machine learning task. Therefore instructions will not specify the exact steps to carry out. Instead, it is part of the assignment to identify promising features, models and preprocessing methods and apply them as appropriate.\n",
    "\n",
    "The overall goal is to predict the fuel efficiency of car models based on historical data collected by the department of energy that can be found at https://www.fueleconomy.gov/feg/download.shtml. In particular, the main goal is to predict the 2018 data from the 2015-2017 data. The main performance metric is R^2 and homework grades will partially depend on your test-set score.\n",
    "\n",
    "On the download page, you should see a table under the \"Datasets and Guides for Individual Model Years\". In the left-most column you'll find links to download the data files for each year. Download the appropriate years and unzip them **in the same directory as your notebook**. When opening the files (hint: `pandas` has a `read_excel` function), use a *relative* path for the files (e.g., `'./2015.xlsx'`) so that I can run your notebook without making any changes to it.\n",
    "\n",
    "The measure of fuel efficiency that you should predict (the 'target') is Combined Unrounded adjusted Fuel Economy(\"Comb Unrd Adj FE - Conventional Fuel\"). Do not use any of the \"tail pipe\" measurement results, only features of the car provided by the manufacturer, to predict the efficiency. You should read the dataset documentation to figure out what this means -- after all, a huge part of the job for any data scientist or machine learning engineer is understanding the data and where it came from! As a hint, many fuel-related columns, such as those containing 'FE' or 'EPA' are not appropriate to use. Additionally, you should be wary of any features that have a suspiciously high correlation with the target -- they are probably related measurements that could not actually be used in real life. You can imagine that in many real-life scenarios these measurements are not yet available when you need to make predictions.\n",
    "\n",
    "Document your process as appropriate, in particular how and when you used the test set. The modelling process is iterative! For example, you may start preprocessing in one way, but by the time you get to training a complicated model realize that a different style of preprocessing is more appropriate, so you return to that step and modify it. However, please lay out the tasks in the below order to facilitate grading.\n",
    "\n",
    "Note: you are free to add extra code blocks as necessary.\n",
    "\n",
    "### Contest (for bonus points)\n",
    "\n",
    "**At any time, you may submit your notebook to me, and I will evaluate it on a special test set.** I will tell you your score and post it on the course webpage with a team name of your choice. There are four ways to receive bonus points:\n",
    "\n",
    "- Have the best score at submission deadline: 4 bonus points = 10% of your hwk3 grade\n",
    "- Have the best score at ANY time (including the very first submission): 3 bonus points = 7.5% of your hwk3 grade\n",
    "- Have a submission that uses a model *not* included in `sklearn`: 2 bonus points = 5% of your hwk3 grade\n",
    "\n",
    "To facilitate evaluating your submissions, please see the final section of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any necessary setup code that all the below blocks will use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Identify Features\n",
    "\n",
    "Read in your data and assemble it into a dataframe or numpy arrays. One way to do this is to use Pandas' `read_excel` function to load in each year's data and concatenate dataframes together. Exactly how you do it is up to you.\n",
    "\n",
    "What features are relevant? Are there any that should be excluded because they 'leak' target information, or may not be available in a real-life prediction task?\n",
    "\n",
    "Show visualizations or statistics to support your selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Preprocessing and Baseline Model\n",
    "\n",
    "Create a simple minimum viable model. Use an initial selection of features, doing appropriate preprocessing and cross-validating a linear model. Feel free to exclude hard-to-understand features or do simplified preprocessing for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Feature Engineering\n",
    "\n",
    "Create derived features and perform more in-depth preprocessing and data cleaning. Does this improve your model? In particular, think about how to encode categorical variables and whether adding interactions (for example using `PolynomialFeatures`, or doing it manually) might help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Any models\n",
    "\n",
    "Use any regression model we discussed (trees, forests, gradient boosting, SVM) to improve your result. You can (and probably should) change your preprocessing and feature engineering to be suitable for the model. You are not required to try all of these models. Tune hyperparameters as appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Feature Selections\n",
    "\n",
    "Identify features that are important for your best model. Which features are most influential, and which features could be removed without decrease in performance? Does removing irrelevant features make your model better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: An Explainable Model\n",
    "\n",
    "Can you create an \"explainable\" model that is nearly as good as your best model? An explainable model should be small enough to be easily inspected -- say, a linear model with few enough coefficients that you can reasonably look at all of them, or a tree with a small number of leaves, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contest Submission\n",
    "\n",
    "Below are 4 code blocks, but you should only use the first and third blocks.\n",
    "\n",
    "The first code block is for you to generate a data set for testing your submission. In the second code block, I will insert code to load in a special test set. This will be available in a `pandas` `DataFrame` variable named `X_contest`.\n",
    "\n",
    "In the third code block, first make any necessary transformations to the dataframe `X_contest`. Then run your best model (you may use variables you defined above) and put the predictions into a variable `pred_contest`. I highly suggest using a `sklearn` pipeline.\n",
    "\n",
    "Leave the final code block blank. I will use this to evaluate your `pred_contest` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an `X_contest` for testing your submission code (optional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave blank. I will use to generate my own `X_contest`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your submission code. Makes transformations to `X_contest` and creates a `pred_contest` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave blank. Here I will evaluate your `pred_contest` variable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
