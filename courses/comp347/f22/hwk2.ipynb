{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "\n",
    "**{{NAME(S) HERE}}**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Due Monday, September 21 by the start of class**. Submit via email. In addition to code, many questions ask for additional explanations. You may answer these with comments in code blocks, or in separate Markdown blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some helpful setup code. Feel free to add whatever else you might need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing, load_breast_cancer\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Predicting House Prices\n",
    "\n",
    "The `sklearn.datasets.fetch_california_housing` dataset contains information on houses in California. Let's train a model to predict house prices!\n",
    "\n",
    "More info on the data can be found [here](http://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1** Fetch the dataset and take a look at it (read the description, make a dataframe and run `describe()`, etc.). Notice that this version is already a little cleaned up compared to the version used in our textbook. \n",
    "\n",
    "**Briefly describe the differences between our version here and the on in the textbook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 code here -- load and examine the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 1.1 here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2** Visualize the univariate distribution (as a histogram) of each feature, and the distribution of the target. Do you notice anything? Is something that you think might require special treatment (just comment what it is; youâ€™re not required to try to fix it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3** Visualize the dependency of the target on each feature (2d scatter plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.4** Split data into training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1.4 Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.5** Evaluate Linear Regression, Ridge, Lasso and ElasticNet using cross-validation with the default hyperparameters (use `cross_val_score`). Note that the \"score\" for these models is $R^2$, AKA the coefficient of determination. Do not preprocess the data in any way. Print out the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# 1.5 Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.6** Now do the same thing but scale the data first using `StandardScaler`. Does it help?\n",
    "\n",
    "Be sure to avoid information leakage; I recommend a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1.6 Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.7** Now let's tune the hyperparameters of the models using GridSearchCV. For right now don't worry too much about what the hyperparameters actually mean.\n",
    "\n",
    "- `LinearRegression` does not have any hyperparameters...so you don't need any grid search at all.\n",
    "- For `Ridge` and `Lasso`, try out some $\\alpha$ (`alpha`) values, and **plot $\\alpha$ (x-axis) against $R^2$ (y-axis)**.\n",
    "- For `ElasticNet`, try out various $\\alpha$ values AND L1 ratios (`l1_ratio`) (at the same time). **Create a heatmap (use `imshow` from `matplotlib`) showing how $R^2$ changes with these values.**\n",
    "\n",
    "Use 5-fold cross validation. I suggest pass `n_jobs=-1` to `GridSearchCV` to run things in parallel (i.e., speed it up). \n",
    "\n",
    "**For all models, print out the best $R^2$ you found. Did the results improve?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Here are some example hyperparameters to try. You are free to come up with your own values.\n",
    "# You'll have to figure out how to apply these to GridSearchCV.\n",
    "ridge_alpha_vals = np.logspace(-3, 3, 20)\n",
    "lasso_alpha_vals = np.logspace(-3, 3, 20)\n",
    "elastic_l1_ratio_vals = [0.01, .1, .5, .9, .98, 1]\n",
    "elastic_alpha_vals = np.logspace(-3, 3, 20)\n",
    "\n",
    "# 1.7 Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.8** Visualize (perhaps with a bar chart) the coefficients of the resulting models (the best ones you found using `GridSearchCV`). Do they agree on which features are important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.8 code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.9** Finally, take your best model with best hyperparameters, retrain it on the whole training set (this might already be done, depending on how you called `GridSearchCV`), and evaluate it on the test set. Show your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.9 code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Predicting Breast Cancer\n",
    "\n",
    "Dataset: sklearn.datasets.load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data, explore, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1** Visualize the univariate distribution of each feature, and the distribution of the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2** Split data into training and test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3** Evaluate Logistic Regression (`LogisticRegression`), linear support vector machines (`LinearSVC`) and nearest centroids (`NearestCentroid`) using cross-validation with the default hyperparameters (use `cross_val_score`). \n",
    "\n",
    "Do not preprocess the data in any way.\n",
    "\n",
    "a. Print out the results (i.e., accuracy for each).\n",
    "\n",
    "b. Look up the two hyperparameters I specified below (`solver='liblinear'` for `LogisticRegression`) and `dual=False` for `LinearSVC`). These both have to do with how the models' parameters are learned. Why do you think I chose the values I did, over the alternatives?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "svm = LinearSVC(dual=False)\n",
    "nc = NearestCentroid()\n",
    "models = [logreg, svm, nc]\n",
    "\n",
    "# 2.3 code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.4** Same thing, but now scale the data first. Does it help?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4 code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5** Now let's tune the hyperparameters of the models using GridSearchCV. Use the following models:\n",
    "\n",
    "- `LogisticRegression`:\n",
    "    - look at the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) and find and explore at least one hyperparameter.\n",
    "- `LinearSVC`:\n",
    "    - `C` can be adjusted; it must be a positive float.\n",
    "- `NearestCentroid`:\n",
    "    - explore the `shrink_threshold` hyperparameter.\n",
    "\n",
    "As above, visualize the performance as a function of the hyperparameters for all three models. If you only used one hyperparameter, your visualizations can just be simple plots (scatter or line). If you used two hyperparameters, use a heatmap. If you used more...well, don't, at least for now.\n",
    "\n",
    "For all models, print out the accuracy you found. Did the results improve? Save the best model for use in question 2.6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 2.5 code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.6** By default, `GridSearchCV` will notice you are doing classification and use `StratifiedKFold`. Change this to plain `KFold`. Do the parameters that are found change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.6 Code here\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.7** Accuracy is not a great metric for classification. Run your grid search again (with `StratifiedKFold`) with `'f1'` as the metric. Compare the best model with the model found in 2.4, comparing both accuracy and f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.7 code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.8** Visualize the coefficients for LogisticRegression and Linear Support Vector Machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.8 code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.9** Finally, take your best model with best hyperparameters, retrain it on the whole training set (this might already be done, depending on how you called `GridSearchCV`), and evaluate it on the test set. Show your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.9 code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Implementing kNN\n",
    "\n",
    "In class we implemented $k$-nearest neighbors with $k=1$. Let's now implement a $k$NN classifier that can use other $k$ values. In the process you'll also learn about Python's object-oriented features. The only method you'll need to finish is `predict`.\n",
    "\n",
    "Functions you may find useful:\n",
    "- `sklearn.metrics.pairwise.euclidean_distances` or `scipy.spatial.distance.euclidean`\n",
    "- `numpy.argpartition` to find the $k$ shortest distances. Alternatively, you could use Python `bisect` module.\n",
    "- `numpy.bincount` and `numpy.argmax`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's the definition of a new class for our classifier.\n",
    "# Notice the constructor is called __init__\n",
    "# All methods take in an explicit parameter \"self\". \n",
    "# It's like C++'s 'this', except in C++ it's not an explicit parameter.\n",
    "class kNNClassifier:\n",
    "    # We only need to remember the number of neighbors; no other initialization\n",
    "    def __init__(self, k):\n",
    "        # Setting a member variable is as simple as assigning one. You don't even need to declare it anywhere.\n",
    "        self.n_neighbors = k\n",
    "    \n",
    "    # Remember we don't need to do much here except save the data.\n",
    "    # We'll assume our data is in the form of a numpy multidimensional array.\n",
    "    def fit(self, data, target):\n",
    "        self.data = data\n",
    "        self.labels = target\n",
    "    \n",
    "    # Take in some data points X and return a numpy array of predictions.\n",
    "    def predict(self, X):\n",
    "        k = self.n_neighbors\n",
    "        predictions = []\n",
    "        # CODE HERE\n",
    "        return np.array(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
