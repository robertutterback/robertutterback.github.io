{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3 -- <<Name(s) here>>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Due Friday, October 23 by 2:00 PM**. You may submit this assignment in groups of 2. Be sure to put your names above. Also, don't forget to submit your data files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this homework is to provide a realistic setting for a machine learning task. Therefore instructions will not specify the exact steps to carry out. Instead, it is part of the assignment to identify promising features, models and preprocessing methods and apply them as appropriate.\n",
    "\n",
    "The overall goal is to predict the fuel efficiency of car models based on historical data collected by the department of energy that can be found at https://www.fueleconomy.gov/feg/download.shtml. In particular, the main goal is to predict the 2018 data from the 2015-2017 data. The main performance metric is R^2 and homework grades will partially depend on your test-set score.\n",
    "\n",
    "The measure of fuel efficiency that you should predict is Combined Unrounded adjusted Fuel Economy(\"Comb Unrd Adj FE - Conventional Fuel\"). Do not use any of the tail pipe measurement results, only features of the car provided by the manufacturer, to predict the efficiency. You should read the dataset documentation to figure out what this means -- after all, a huge part of any data scientist's or machine learning engineer's job is understanding the data and where it came from! As a hint, many fuel-related columns, such as thsoe containing 'FE' or 'EPA' are not appropriate to use. You can imagine that in many real-life scenarios these measurements are not yet available when you need to make predictions.\n",
    "\n",
    "Document your process as appropriate, in particular how and when you used the test set. The modelling process is iterative! For example, you may start preprocessing in one way, but by the time you get to training a complicated model realize that a different style of preprocessing is more appropriate, so you return to that step and modify it. However, please lay out the tasks in the below order to facilitate grading.\n",
    "\n",
    "Note: you are free to add extra code blocks as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any necessary setup code that all the below blocks will use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Identify Features\n",
    "\n",
    "Read in your data and assemble it into a dataframe or numpy arrays. One way to do this is to use Pandas' `read_excel` function to load in each year's data and concatenate dataframes together. Exactly how you do it is up to you.\n",
    "\n",
    "What features are relevant? Are there any that should be excluded because they 'leak' target information, or may not be available in a real-life prediction task?\n",
    "\n",
    "Show visualizations or statistics to support your selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Preprocessing and Baseline Model\n",
    "\n",
    "Create a simple minimum viable model. Use an initial selection of features, doing appropriate preprocessing and cross-validating a lienar model. Feel free to exclude features or do simplified prepcoressing for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['column name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Feature Engineering\n",
    "\n",
    "Create derived features and perform more in-depth preprocessing and data cleaning. Does this improve your model? In particular, think about how to encode categorical variables and whether adding interactions (for example using PolynomialFeatures, or doing it manually) might help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Any models\n",
    "\n",
    "Use any regression model we discussed (trees, forests, gradient boosting, SVM) to improve your result. You can (and probably should) change your preprocessing and feature engineering to be suitable for the model. You are not required to try all of these models. Tune hyperparameters as appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Feature Selections\n",
    "\n",
    "Identify features that are important for your best model. Which features are most influential, and which features could be removed without decrease in performance? Does removing irrelevant features make your model better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: An Explainable Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
