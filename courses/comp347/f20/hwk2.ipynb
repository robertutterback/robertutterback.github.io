{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Due Wednesday, September 16 by 10:00 AM**. Submit via email. Answer any non-code questions as comments in code blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some helpful setup code. Feel free to add whatever else you might need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing, fetch_covtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Predicting House Prices\n",
    "\n",
    "The `sklearn.datasets.fetch_california_housing` dataset contains information on houses in California. Let's train a model to predict house prices!\n",
    "\n",
    "More info on the data can be found [here](http://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1** Visualize the univariate distribution (as a histogram) of each feature, and the distribution of the target. Do you notice anything? Is something that you think might require special treatment (comment what it is, youâ€™re not required to try to fix it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Code here\n",
    "fetch_covtype()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2** Visualize the dependency of the target on each feature (2d scatter plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3** Split data in training and test set. Evaluate Linear Regression (OLS), Ridge, Lasso and ElasticNet using cross-validation with the default hyperparameters. \n",
    "\n",
    "Print out the results. Does scaling the data with StandardScaler help?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "# split here\n",
    "\n",
    "# Scale the data (don't need to change)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "# Here's an example with LinearRegression\n",
    "model = LinearRegression()\n",
    "score = np.mean(cross_val_score(model, X_train_scaled, y_train, cv=10))\n",
    "print(f\"Linear Regression (default hyperparameters): {score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.4** Tune the hyperparameters of the models using GridSearchCV. Do the results improve? Visualize the dependence of the validation score on the hyperparameters for Ridge, Lasso and ElasticNet.\n",
    "\n",
    "`LinearRegression` does not have any hyperparameters.\n",
    "\n",
    "For `Ridge` and `Lasso`, try out some alpha values, and plot alpha (x-axis) against $R^2$ (y-axis).\n",
    "\n",
    "For `ElasticNet`, try out various alpha values AND L1 ratios (at the same time). Create a heatmap showing how $R^2$ changes with these values.\n",
    "\n",
    "For all models, print out the best $R^2$ you found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Here are some example hyperparameters to try. You are free to come up with your own values. \n",
    "# You'll have to figure out how to apply these to GridSearchCV.\n",
    "ridge_alpha_vals = np.logspace(-3, 2.7, 20)\n",
    "lasso_alpha_vals = np.logspace(-6, 0, 20)\n",
    "elastic_l1_ratio_vals = [0.01, .1, .5, .9, .98, 1]\n",
    "elastic_alpha_vals = np.logspace(-3, 3, 20)\n",
    "\n",
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.5** Visualize the coefficients of the resulting models (the best ones you found using `GridSearchCV`). Do they agree on which features are important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Classifying Forest Cover Type\n",
    "\n",
    "Dataset: sklearn.datasets.fetch_covtype\n",
    "\n",
    "Details: [https://archive.ics.uci.edu/ml/datasets/covertype\n",
    "](https://archive.ics.uci.edu/ml/datasets/covertype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1** Visualize the univariate distribution of each feature, and the distribution of the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2** Split data into training and test set. Evaluate Logistic Regression, linear support vector machines and nearest centroids using cross-validation. How different are the results? How does scaling the data with StandardScaler influence the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "\n",
    "# Some of these models can take a long time with the defaults, especially for GridSearchCV below.\n",
    "# I found these options were reasonably fast, though the accuracy does suffer.\n",
    "# Feel free to try out others.\n",
    "# SGD with log loss = fast, approximate logistic regression\n",
    "logreg_sgd = SGDClassifier(loss='log', penalty=None, max_iter=100, tol=1e-3)\n",
    "# SGD with hinge los = fast, approximate Linear support vector machine\n",
    "lsvm_sgd = SGDClassifier(loss='hinge', penalty=None, max_iter=100, tol=1e-3)\n",
    "nc = NearestCentroid()\n",
    "\n",
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3** Tune the parameters using GridSearchCV. Do the results improve? Visualize the performance as function of the hyperparameters for all three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.4** Change the cross-validation strategy from 'stratified k-fold' to 'kfold' with shuffling. Do the parameters that are found change? Do they change if you change the random seed of the shuffling? Or if you change the random state of the split into training and test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5** Visualize the coefficients for LogisticRegression and Linear Support Vector Machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Implementing kNN\n",
    "\n",
    "In class we implemented $k$-nearest neighbors with $k=1$. Let's now implement a $k$NN classifier that can use other $k$ values. In the process you'll also learn about Python's object-oriented features. The only method you'll need to finish is `predict`.\n",
    "\n",
    "Functions you may find useful:\n",
    "- `sklearn.metrics.pairwise.euclidean_distances` or `scipy.spatial.distance.euclidean`\n",
    "- `numpy.argpartition` to find the $k$ shortest distances. Alternatively, you could use Python `bisect` module.\n",
    "- `numpy.bincount` and `numpy.argmax`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's the definition of a new class for our classifier.\n",
    "# Notice the constructor is called __init__\n",
    "# All methods take in an explicit parameter \"self\". \n",
    "# It's like C++'s 'this', except in C++ it's not an explicit parameter.\n",
    "class kNNClassifier:\n",
    "    # We only need to remember the number of neighbors; no other initialization\n",
    "    def __init__(self, k):\n",
    "        # Setting a member variable is as simple as assigning one. You don't even need to declare it anywhere.\n",
    "        self.n_neighbors = k\n",
    "    \n",
    "    # Remember we don't need to do much here except save the data.\n",
    "    # We'll assume our data is in the form of a numpy multidimensional array.\n",
    "    def fit(self, data, target):\n",
    "        self.data = data\n",
    "        self.labels = target\n",
    "    \n",
    "    # Take in some data points X and return a numpy array of predictions.\n",
    "    def predict(self, X):\n",
    "        k = self.n_neighbors\n",
    "        predictions = []\n",
    "        # CODE HERE\n",
    "        return np.array(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
